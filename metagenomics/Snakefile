#############################################
#SNAKEFILE FOR QC using Kracken2 and Bracken#
#############################################

#Version History:
# Jan20: some bug fixes by fmk
# 13Dec19: created by JSB at LL Hackathon 2019

#Reminders:
# Put your own email address in cluster.slurm.json so that you get emails about failures. No one else wants your slurm emails.

''' VARIABLES '''
#USER defined variables (in theory do not need to be touched)
spls = "samples.csv"

import sys
SCRIPTS_DIRECTORY = "/home/markey/mit_lieberman/scripts"
sys.path.insert(0, SCRIPTS_DIRECTORY)

from read_move_link_samplesCSV import *



''' PRE-SNAKEMAKE '''
# define couple of lists from samples.csv
# Format: Path,Sample,ReferenceGenome,ProviderName,Subject
[PATH_ls, SAMPLE_ls, REF_Genome_ls, PROVIDER_ls, CLADEID_ls] = read_samplesCSV(spls)
# Write sample_info.csv for each sample
split_samplesCSV(PATH_ls,SAMPLE_ls,REF_Genome_ls,PROVIDER_ls,CLADEID_ls)

CLADES_ls = set(CLADEID_ls)


# set(list_patient) provides only unique clade IDs


''' SNAKEMAKE '''
rule all:
	input:
		# # Only data links # #
		expand("data/{sampleID}/R1.fq.gz",sampleID=SAMPLE_ls),
		expand("data/{sampleID}/R2.fq.gz",sampleID=SAMPLE_ls),
		# #Through all steps# #
		expand("/nfs/tamilab001/c3ddb-scratch-mit_lieberman/reference_genomes/{reference}/genome_bowtie2.1.bt2",reference=set(REF_Genome_ls)),
		expand("3-bowtie2/{sampleID}_ref_{reference}_aligned.sam", sampleID=SAMPLE_ls, reference=REF_Genome_ls),
		expand("3-bowtie2/{sampleID}_ref_{reference}_unaligned.1.fastq", sampleID=SAMPLE_ls, reference=REF_Genome_ls),
		expand("3-bowtie2/{sampleID}_ref_{reference}_unaligned.2.fastq", sampleID=SAMPLE_ls, reference=REF_Genome_ls),
		expand("1-kraken2-newdb/{sampleID}_{reference}_filt_krakenRep.txt", sampleID=SAMPLE_ls,reference=REF_Genome_ls),
		expand("2-bracken-newdb/{sampleID}_{reference}_filt.bracken",sampleID=SAMPLE_ls,reference=REF_Genome_ls),
		expand("3-filt-bracken/{sampleID}_{reference}.filt9606.bracken", sampleID=SAMPLE_ls, reference=REF_Genome_ls),
		#marking duplicates using samtools
		#expand("4-markdup/{sampleID}_ref{reference}_stats.txt",sampleID=SAMPLE_ls, reference=REF_Genome_ls),
		# Including cleanup # #


#PART 0: prepare filtered, clean FASTQ samples

rule make_data_links:
	# NOTE: All raw data needs to be names fastq.gz. No fq! The links will be names fq though.
	input:
		sample_info_csv=ancient("data/{sampleID}/sample_info.csv"),
	output:
		# Recommend using symbolic links to your likely many different input files
		fq1="data/{sampleID}/R1.fq.gz",
		fq2="data/{sampleID}/R2.fq.gz",
	run:
		# get stuff out of mini csv file
		with open(input.sample_info_csv,'r') as f:
			this_sample_info = f.readline() # only one line to read
		this_sample_info = this_sample_info.strip('\n').split(',')
		path = this_sample_info[0] # remember python indexing starts at 0
		paths = path.split(' ')
		sample = this_sample_info[1]
		provider = this_sample_info[3]
		# make links
		if len(paths)>1:
			cp_append_files(paths, sample, provider)
		else:
			makelink(path, sample, provider)

rule cutadapt:
	input:
		# Recommend using symbolic links to your likely many different input files
		fq1 = rules.make_data_links.output.fq1,
		fq2 = rules.make_data_links.output.fq2,
	output:
		fq1o="0-tmp/{sampleID}_R1_trim.fq.gz",
		fq2o="0-tmp/{sampleID}_R2_trim.fq.gz",
	conda:
		"envs/cutadapt.yaml"
	shell:
		"cutadapt -a CTGTCTCTTAT -o {output.fq1o} {input.fq1} ;"
		"cutadapt -a CTGTCTCTTAT -o {output.fq2o} {input.fq2} ;"

rule sickle2050:
	input:
		fq1o = rules.cutadapt.output.fq1o,
		fq2o = rules.cutadapt.output.fq2o,
	output:
		fq1o="1-data_processed/{sampleID}/filt1.fq.gz",
		fq2o="1-data_processed/{sampleID}/filt2.fq.gz",
		fqSo="1-data_processed/{sampleID}/filt_sgls.fq.gz",
	conda:
		"envs/sickle-trim.yaml"
	shell:
		"sickle pe -g -f {input.fq1o} -r {input.fq2o} -t sanger -o {output.fq1o} -p {output.fq2o} -s {output.fqSo} -q 20 -l 50 -x -n"

rule refGenome_index: 
	input:
		fasta="/nfs/tamilab001/c3ddb-scratch-mit_lieberman/reference_genomes/{reference}/genome.fasta"
	params:
		"/nfs/tamilab001/c3ddb-scratch-mit_lieberman/reference_genomes/{reference}/genome_bowtie2",
	output:
		bowtie2idx="/nfs/tamilab001/c3ddb-scratch-mit_lieberman/reference_genomes/{reference}/genome_bowtie2.1.bt2"
	conda:
		"envs/bowtie2.yaml"
	shell:
		"bowtie2-build -q {input.fasta} {params} "


rule bowtie2:
	input:
		fq1=rules.sickle2050.output.fq1o,
		fq2=rules.sickle2050.output.fq2o,
		bowtie2idx=rules.refGenome_index.output.bowtie2idx # put here, so rule botie2 only executed after rule refGenome_index done
	output:
		sam_aligned="3-bowtie2/{sampleID}_ref_{reference}_aligned.sam",
		micro_f="3-bowtie2/{sampleID}_ref_{reference}_unaligned.1.fastq",
		micro_r="3-bowtie2/{sampleID}_ref_{reference}_unaligned.2.fastq",
	params:
		refGenome="/nfs/tamilab001/c3ddb-scratch-mit_lieberman/reference_genomes/{reference}/genome_bowtie2",
		fqU="3-bowtie2/{sampleID}_ref_{reference}_unaligned.fastq", # just a prefix. 
	conda:
		"envs/bowtie2.yaml"
	shell:
		"bowtie2 --threads 8 -X 2000 --no-mixed --dovetail --un-conc {params.fqU} -x {params.refGenome} -1 {input.fq1} -2 {input.fq2} -S {output.sam_aligned}"

rule sam2bam:
	input:
		samA=rules.bowtie2.output.sam_aligned,
	params:
		fqU1=rules.bowtie2.output.micro_f,
		fqU2=rules.bowtie2.output.micro_r,
	output:
		bamA="3-bowtie2/{sampleID}_ref_{reference}_aligned.sorted.bam",
	conda:
		"envs/samtools15_bcftools12.yaml"
	shell:
		# 8 threads coded into json
		" samtools view -bS {input.samA} | samtools sort - -o {output.bamA} ;"
		" samtools index {output.bamA} ;"

rule fixmate:
	input:
		bamA=rules.sam2bam.output.bamA,
	output:
		fixbam="4-markdup/{sampleID}_ref_{reference}_fix.bam",
	conda:
		"envs/samtools10.yaml"
	shell:
		"samtools sort -n {input.bamA}|samtools fixmate -m - {output.fixbam}"

rule markdup:
	input:
		fixbam=rules.fixmate.output.fixbam,
	output:
		mkdupbam="4-markdup/{sampleID}_ref_{reference}_markdup.bam",
		stats="4-markdup/{sampleID}_ref{reference}_stats.txt",
	conda:
		"envs/samtools10.yaml"
	shell:
		"samtools sort {input.fixbam}| samtools markdup - {output.mkdupbam} -f {output.stats}"


""" KRAKEN """

rule kraken2:
	#quality assessment based only on fwd 
	input:
		fa1o = "3-bowtie2/{sampleID}_ref_{reference}_unaligned.1.fastq",
		fa2o = "3-bowtie2/{sampleID}_ref_{reference}_unaligned.2.fastq",
	output:
		report="1-kraken2-newdb/{sampleID}_{reference}_filt_krakenRep.txt",
		#seq_results="0-tmp/{sampleID}_{reference}_filt_krakSeq.txt",
	conda:
		"envs/kraken2_bracken.yaml",
	shell:
		"kraken2 --threads 4 "
		"--db /orcd/nese/tami/001/databases/krakendb_plus_pf --paired {input} "
		"--report {output.report} "

rule bracken:
	input:
		report = rules.kraken2.output.report,
	output:
		bracken_rep="2-bracken-newdb/{sampleID}_{reference}_filt.bracken",
	conda:
		"envs/kraken2_bracken.yaml",
	shell:
		"bracken -d /orcd/nese/tami/001/databases/krakendb_plus_pf -i {input.report} -o {output.bracken_rep} "

rule bracken_filter:
	input:
		bracken=rules.bracken.output.bracken_rep,
	output:
		filt_bracken_rep="3-filt-bracken/{sampleID}_{reference}.filt9606.bracken",
	conda:
		"envs/kraken2_bracken.yaml",
	shell :
		"python filter_bracken_out.py --exclude 9606 -i {input.bracken} -o {output.filt_bracken_rep}"


#if you just want to run kracken straight from F fastq reads instead of from bowtie2 output
# rule FQ2FA:
# 	# Kracken only uses forward reads
# 	input:
# 		fq1o=rules.sickle2050.output.fq1o,
# 	output:
# 		fa1o="0-tmp/{sampleID}_1.fa",
# 	shell:
# 		# set +o pipefail; necessary to prevent pipefail (zcat runs but head is done)
# 		"set +o pipefail; "
# 		"gzip -cd {input.fq1o} | scripts/fq2fa_sed.sh /dev/stdin > {output.fa1o} ;"


# """ KRAKEN """

# rule kraken2:
# 	#quality assessment based only on fwd 
# 	input:
# 		fa1o = rules.FQ2FA.output.fa1o,
# 	output:
# 		report="1-kraken2/{sampleID}_krakenRep.txt",
# 		seq_results="0-tmp/{sampleID}_krakSeq.txt.gz",
# 	conda:
# 		"envs/kraken2_bracken.yaml",
# 	shell:
# 		"kraken2 --threads 20 "
# 		"--db /nfs/tamilab001/c3ddb-scratch-mit_lieberman/tools/databases/kraken2/ {input} "
# 		"--report {output.report} |gzip > {output.seq_results} "

# rule bracken:
# 	input:
# 		report = rules.kraken2.output.report,
# 	output:
# 		bracken_rep="2-bracken/{sampleID}.bracken",
# 	conda:
# 		"envs/kraken2_bracken.yaml",
# 	shell:
# 		"bracken -d /nfs/tamilab001/c3ddb-scratch-mit_lieberman/tools/databases/kraken2/ -i {input.report} -o {output.bracken_rep} "
